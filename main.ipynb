{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoritmo_euclides():\n",
    "  a = np.random.randint(1, 101)\n",
    "  b = np.random.randint(1, 101)\n",
    "  return a, b, math.gcd(a, b)\n",
    "\n",
    "def create_data(n):\n",
    "  data = []\n",
    "\n",
    "  while len(data) < n:\n",
    "    a, b, mdc = algoritmo_euclides()\n",
    "    data.append([a, b, mdc])\n",
    "\n",
    "  # Escreve todos os dados em um arquivo\n",
    "  with open(\"data.txt\", \"w\") as f:\n",
    "    for row in data:\n",
    "      f.write(\"\\t\".join(map(str, row)) + \"\\n\")\n",
    "\n",
    "def load_data(file_path):\n",
    "  with open(file_path, \"r\") as f:\n",
    "    data = [line.strip().split(\"\\t\") for line in f.readlines()]\n",
    "\n",
    "  y_in = np.array([[int(d[0]), int(d[1])] for d in data])\n",
    "  mdc = np.array([int(d[2]) for d in data])\n",
    "\n",
    "  # Primeira divisão entre treinamento e teste\n",
    "  y_train, y_test, mdc_train, mdc_test = train_test_split(y_in, mdc, test_size=0.5, shuffle=False, random_state=42)\n",
    "  # Segunda divisão dentro do conjunto de teste, entre teste e validação\n",
    "  y_test, y_validation, mdc_test, mdc_validation = train_test_split(y_test, mdc_test, test_size=0.5, shuffle=False, random_state=42)\n",
    "\n",
    "  return y_train, y_test, y_validation, mdc_train, mdc_test, mdc_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000000\n",
    "create_data(n)\n",
    "\n",
    "y_train, y_test, y_validation, mdc_train, mdc_test, mdc_validation = load_data(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, y_validation, mdc_train, mdc_test, mdc_validation = load_data(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rede Neural\n",
    "model = Sequential([\n",
    "  Embedding(input_dim=101, output_dim=64), # Input Layer\n",
    "  LSTM(64, return_sequences=True),\n",
    "  LSTM(64, return_sequences=True),\n",
    "  LSTM(64),\n",
    "  Dense(1, activation=\"linear\") # Output layer\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer = \"adam\", loss= \"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Callback para parar o treinamento se a métrica monitorada não melhorar\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", patience=10)\n",
    "\n",
    "#Treina o modelo\n",
    "history = model.fit(y_train, mdc_train, epochs=100, batch_size=400, verbose=1, callbacks=[early_stopping], validation_data=(y_validation, mdc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a figura e os subplots\n",
    "fig, axs = plt.subplots(1,2, figsize=(14, 6))\n",
    "\n",
    "# Plotar o gráfico da CUSTO em função da época\n",
    "axs[0].plot(history.history['loss'], label=\"Custo (Dados de treinamento)\")\n",
    "axs[0].plot(history.history['val_loss'], label=\"Custo (Dados de teste)\")\n",
    "axs[0].set_title('Custo em função da Época')\n",
    "axs[0].set_xlabel('Época')\n",
    "axs[0].set_ylabel('Custo')\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plotar o gráfico da PRECISÃO em função da época\n",
    "axs[1].plot(history.history['accuracy'], label=\"Precisão (Dados de treinamento)\")\n",
    "axs[1].plot(history.history['val_accuracy'], label=\"Precisão (Dados de teste)\")\n",
    "axs[1].set_title('Precisão em função da Época')\n",
    "axs[1].set_xlabel('Época')\n",
    "axs[1].set_ylabel('Precisão')\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Ajustar o layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar a figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(y_validation)\n",
    "\n",
    "# Precisões\n",
    "precisions = []\n",
    "\n",
    "menor = []\n",
    "maior = []\n",
    "entre = []\n",
    "\n",
    "for i in range(len(y_validation)):\n",
    "  real_value = mdc_validation[i]  # Valor real esperado\n",
    "  predicted_value = predictions[i][0] # Valor previsto pela rede \n",
    "  precisions.append( (predicted_value / real_value) * 100 )\n",
    "\n",
    "# Separa as precisões nas respectivas listas\n",
    "for i in range(len(precisions)):\n",
    "  if precisions[i] > 100:\n",
    "    maior.append(precisions[i])\n",
    "  elif precisions[i] < 90:\n",
    "    menor.append(precisions[i])\n",
    "  else:\n",
    "    entre.append(precisions[i])\n",
    "\n",
    "print(f\"Dados (Validação): {len(precisions)}\")\n",
    "print(f\"Dados com precisão entre 90% e 100%: {len(entre)}\")\n",
    "print(f\"Dados com precisão menor que 90%: {len(menor)}\")\n",
    "print(f\"Dados com precisão maior que 100%: {len(maior)}\")\n",
    "\n",
    "print(f\"MENOR: {min(precisions)}%\")\n",
    "print(f\"MAIOR: {max(precisions)}%\")\n",
    "\n",
    "# Mostra as precisões\n",
    "for i in range(len(precisions)):\n",
    "  print(f\"\\nMDC de {y_validation[i][0], y_validation[i][1]} - Valor real: {mdc_validation[i]} - Valor calculado: {predictions[i][0]} - Precisão: {precisions[i]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtém os pesos e bias da camada de Embedding\n",
    "embedding_weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Obtém os pesos e bias da primeira camada LSTM\n",
    "lstm1_weights, lstm1_recurrent_weights, lstm1_bias = model.layers[1].get_weights()\n",
    "\n",
    "# Obtém os pesos e bias da segunda camada LSTM\n",
    "lstm2_weights, lstm2_recurrent_weights, lstm2_bias = model.layers[2].get_weights()\n",
    "\n",
    "# Obtém os pesos e bias da terceira camada LSTM\n",
    "lstm3_weights, lstm3_recurrent_weights, lstm3_bias = model.layers[3].get_weights()\n",
    "\n",
    "# Obtém os pesos e bias da camada densa\n",
    "dense_weights, dense_bias = model.layers[4].get_weights()\n",
    "\n",
    "# Função para plotar heatmaps em subplots\n",
    "def plot_weights_and_biases(weights, bias, title_weights, title_bias):\n",
    "  plt.figure(figsize=(14, 6))\n",
    "    \n",
    "  # Plot weights\n",
    "  plt.subplot(1, 2, 1)\n",
    "  sns.heatmap(weights, cmap=\"viridis\", linewidths=.5)\n",
    "  plt.title(title_weights)\n",
    "    \n",
    "  # Plot bias\n",
    "  plt.subplot(1, 2, 2)\n",
    "  sns.heatmap(bias.reshape(1, -1), cmap=\"viridis\", linewidths=.5)\n",
    "  plt.title(title_bias)\n",
    "    \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# Mapa de calor dos pesos e bias da camada de Embedding\n",
    "plot_weights_and_biases(embedding_weights, embedding_weights.mean(axis=0), 'Embedding Layer Weights', 'Embedding Layer Bias')\n",
    "\n",
    "# Mapa de calor dos pesos e bias da primeira camada LSTM\n",
    "plot_weights_and_biases(lstm1_weights, lstm1_bias, 'LSTM 1 Weights', 'LSTM 1 Bias')\n",
    "\n",
    "# Mapa de calor dos pesos e bias da segunda camada LSTM\n",
    "plot_weights_and_biases(lstm2_weights, lstm2_bias, 'LSTM 2 Weights', 'LSTM 2 Bias')\n",
    "\n",
    "# Mapa de calor dos pesos e bias da terceira camada LSTM\n",
    "plot_weights_and_biases(lstm3_weights, lstm3_bias, 'LSTM 3 Weights', 'LSTM 3 Bias')\n",
    "\n",
    "# Mapa de calor dos pesos e bias da camada densa\n",
    "plot_weights_and_biases(dense_weights, dense_bias, 'Dense Layer Weights', 'Dense Layer Bias')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
